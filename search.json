[
  {
    "objectID": "blogs/blog.html",
    "href": "blogs/blog.html",
    "title": "Blog",
    "section": "",
    "text": "Benchmarking\n\n    \n\n    \n    \n    \n\n    \n    \n        The AutoML Benchmark"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lab",
    "section": "",
    "text": "Welcome to the Automated Machine Learning lab at Eindhoven University of Technology!"
  },
  {
    "objectID": "index.html#mission",
    "href": "index.html#mission",
    "title": "Lab",
    "section": "Mission",
    "text": "Mission\nOur mission is to scientifically understand and build AI systems with advanced capabilities, and make AI accessible to all to benefit all of humanity.\nWe invent new neural network architectures and train them in new ways to learn better and faster, study models systematically, and use our insights to automate this process so that AI systems can self-assemble and optimize themselves. Everything we create is open-source and crafted with user-friendliness in mind.\nIn this pursuit, we created OpenML, an global open platform with myriad curated datasets, AI models, and experiments, for streamlining machine learning research and making it accessible to all. We perform cutting-edge research on Automated Machine Learning (AutoML), Meta-Learning, Continual Learning, Foundation Models, Open-Endedness, and related fields, and validate our methods in projects that tackle sustainable development goals, including health care, food security, and climate change.\nYou can find our work in top AI conferences and journals, and we take pride in good engineering and open science to build AI models and systems that are widely used by people every day.\nWe are integrated in the Data and AI cluster, which does excellent research in all aspects of AI."
  },
  {
    "objectID": "index.html#recent-highlights",
    "href": "index.html#recent-highlights",
    "title": "Lab",
    "section": "Recent highlights",
    "text": "Recent highlights\n\n\n\n\nWe are hiring!\n\nOur team is growing! We have 7 new openings for PhD students, PostDocs, and Research Engineers for research on foundation models, AutoML, and industry collaboration. Apply now!\n\n\n\n\nNeurIPS 2024 Spotlight for Croissant\n\nCroissant is a new standard for describing machine learning datasets, making it easier to share and reuse data and load it automatically into AI libraries. Joined work with Google, HuggingFace, Kaggle, MLCommons, and many more. Join us at NeurIPS 2024!\n\n\n\n\nICML 2024 Spotlight for MALIBO\n\nMALIBO is a neural network that meta-learns how to tune hyperparameters - it learns across many prior tasks to tune models much more efficiently than other techniques. Jiarong Pan will present his work as a spotlight talk at ICML 2024."
  },
  {
    "objectID": "index.html#join-us",
    "href": "index.html#join-us",
    "title": "Lab",
    "section": "Join us!",
    "text": "Join us!\nPhD, PostDoc, or AI Engineer positions: please check out our open positions. Without an open position, you need to be self-funded or have a scholarship.\nVisiting researchers: We love discussing new ideas and collaborations! Note that we generally expect you to stay for at least a few months. Our lab is generally not able to offer paid internships."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Lab",
    "section": "Contact",
    "text": "Contact\nE-mail: openml-labs@tue.nl\nAddress: Groene Loper 5, Metaforum 7.104, 5600 MB Eindhoven, The Netherlands\n\nThis website is powered by Quarto, with thanks to Drew Dimmery."
  },
  {
    "objectID": "projects/projects.html",
    "href": "projects/projects.html",
    "title": "Projects",
    "section": "",
    "text": "2024\nAssessment of Learning technologies and Frameworks for Intelligent and Ethical AIEU Horizon Europe (2024-2027)ALFIE aims to build an AutoML platform that streamlines AI evaluation, ensuring performance aligns with ethical standards and societal values.\n        \n        Project website\n    \nSYNERGIESEU Horizon Europe (2024-2027)SYNERGIES will enhance the development, training, virtual testing, and validation of cooperative, connected and automated mobility systems.\n        \n        Project website\n    \nEDIH-SNLEU Digital Europe (2024-2025)The European Digital Innovation Hub South Netherlands aims to accellerate the digital transformation of manufacturing and maintenance SMEs.\n        \n        Project website\n    \nAutomated Machine Learning for allDutch Science Foundation, Open Science Fund (2024-2025)This project leverages OpenML and AutoML to automatically build AI models and provide intuitive reports to help scientists make progress across many different fields.\n        \n        Project website\n    \n2022\nMachine Learning for building renovationsDutch Government (2022-2026)To make cities more sustainable, this project uses machine learning to predict the energy performance of buildings and optimize renovation strategies.\n        \n        Project website\n    \nDigital Twin of a Vertical FarmDutch Science Foundation, Merian Fund (2022-2026)Vertical farming allows us to grow more food using less resources. We use AI to model plants in 3D to understand how different light, CO2 and temperature scenarios impact plant growth and photosynthesis.\n        \n        Project website\n    \nAI4EuropeEU Horizon Europe (2022-2025)The AI-on-Demand platform (AIoD) is a community-driven platform designed to empower European research and innovation in Artificial Intelligence (AI).\n        \n        Project website\n    \n2020\nStairway to AIEU Horizon 2020 (2020-2024)The StairwAI project aims to provide a matchmaking service for users of the AI-on-Demand platform to easily find AI assets, experts, knowledge, hardware resource providers and much more.\n        \n        Project website\n    \nContinuous monitoring in personal and physical healthITEA Inno4Health (2020-2024)Inno4Health stimulates continuous monitoring in personal and physical health, improving patient care and athlete performance.\n        \n        Project website\n    \nMulti Modal PhotochemistryDutch Science Foundation, TTW (2020-2024)In this project, we aimed to optimize the photochemical synthesis of complex molecules using machine learning.\nTAILOR Network of AI ExcellenceEU Horizon 2020 (2020-2024)TAILOR is one of the first European networks of research excellence in AI, focussing on Trustworthy AI.\n        \n        Project website\n    \nSkyHigh: Leveraging AI in Vertical FarmingDutch Science Foundation (2020-2024)Vertical farming allows us to grow more food using less resources. We use AI to track plant growth non-invasively and optimize growth.\n        \n        Project website\n    \n2019\nEducational platform for machine learning and medical image analysisTU Eindhoven, BOOST (2019-2025)AI education should be scalable and engaging. This project aims to leverage OpenML for AI-related university courses, challenging students to build the best AI models in an engaging environment.\n        \n        Project website\n    \nThe AutoML GymAmazon Research Award (2019-2020)This project aimed to evolve AutoML systems (agents) in an environment of increasingly difficult tasks, in which AutoML agents can be uploaded as docker images and run on AWS infrastructure.\n        \n        Project website\n    \n2017\nDynamic Data Analytics through Automatically Constructed Machine Learning PipelinesDutch Science Foundation, Commit2Data (2017-2021)This project created new online automated machine learning pipelines, new methods for multi-variate time series prediction, and new approaches for early stage Parkinson's disease diagnostics from videos.\n        \n        Project website\n    \nData Driven Discovery of ModelsDARPA (2017-2021)The first DARPA challenge on AutoML, the Data-Driven Discovery of Models (D3M) program developed automated methods to create empirical models of real, complex processes. It also lead to the creation of the AutoML benchmark.\n        \n        Project website\n    \n2016\nA Cloud-Based Platform for AutoMLMicrosoft Azure Research Award (2016-2016)With sponsorship from Microsoft, we ran the first large-scale machine learning benchmarks on Azure, which are still accessible on OpenML today.\n        \n        Project website\n    \n2012\nMassively Collaborative Machine LearningDutch Science Foundation, Free Competition (2012-2016)This project created OpenML, an open science platform for sharing data, code, and experiments in machine learning.\n        \n        Project website\n    \nMLOpen Machine Learning PlatformEU PASCAL Harvest (2012-2013)This exploratory project brought together scientists and engineers to create an open machine learning platform, forming the foundation of the OpenML community."
  },
  {
    "objectID": "join/join.html",
    "href": "join/join.html",
    "title": "Join us!",
    "section": "",
    "text": "Impressions of our campus.\n\n\n\nCurrent openings (7)\nWe currently have room for seven outstanding machine learning Ph.D.Â students, PostDocs, and Engineers. The vacancies will remain open until the positions are filled. Apply now!\n\nPhD in Open-Source Foundation Models (2 positions)\nJoin a groundbreaking project to develop a next-generation, open-source family of foundation models. We are seeking a proficient and talented PhD student with a true passion for AI. You will play a pivotal role in a team exploring new large model architectures, novel efficient finetuning and adaptation techniques, refining data to enhance learning and generalizability, creating benchmarks, and ensuring AI safety. [4 year position]\n\n\nPostdoctoral Fellow in Open-Source Foundation Models (2 positions)\nJoin a groundbreaking project to develop a next-generation, open-source family of foundation models. We are seeking a proficient and talented researcher who is passionate about large models and learning to learn. You will play a pivotal role in a team exploring new model architectures, novel efficient finetuning and adaptation techniques, refining data to enhance learning and generalizability, creating benchmarks, and ensuring AI safety. [3 year position]\n\n\nPostdoctoral Fellow in Automated Machine Learning for Safe AI\nWe are seeking a passionate and talented research Scientist to lead the development of an AutoML platform that integrates cutting-edge machine learning techniques with natural language interfaces. You will work closely with an exceptional team of engineers and researchers to design a system that makes AI more accessible, impactful, and responsible. [2 year position]\n\n\nPostDoc/Expert in AI-driven innovation\nLooking to make real-world impact with AI? Weâre hiring a AI expert to help companies in the Netherlands unlock AIâs potential! Join our cutting-edge lab, collaborate with businesses, and co-create solutions that drive innovation, sustainability, and real-world impact. [1 year position]\n\n\nResearch Engineer in Open-Source Foundation Models (Will appear soon!)\nWe are looking for an exceptional research engineer with a passion for AI and open-source development. In this role, you will design and build cutting-edge tools and software that will shape the future of foundation models, used by millions of people worldwide. [3 year position]\nYou can also check out other positions in our department.\n\n\n\nWho we are looking for\nWe are seeking exceptional individuals who aspire to leave a mark on the world of machine learning and push humanity forward\n\nFearless Explorers: Visionaries who dare to think big, embrace curiosity, and thrive on pushing the boundaries of innovation.\nDedicated Builders: Innovators who turn ambitious ideas into reality, creating solutions with real-world impact.\nEmpowered Leaders: Changemakers ready to unlock their full potential, inspire others, and define the future of machine learning.\n\nWe especially appreciate people who are curious and open-minded, self-driven and collaborative, kind and respectful, and who contribute to our shared passion for research and exploration. If youâre passionate about making a difference and pursuing excellence, we want you to be part of our journey.\n\n\nHow we will empower you\n\nWe cultivate an environment that inspires and supports world-class research. Our focus is on quality over quantity, encouraging innovative, blue-sky thinking while embracing openness, transparency, and learning from mistakes. Above all, we prioritize an excellent work-life balance, with minimal meetings, plenty of time for focused work, and numerous opportunities to learn and collaborate with one another.\n\nFully Funded for Success\nAll positions are fully funded, so you can focus entirely on your research and growth. PhD positions are always funded for 4 years. PostDoc and Research Engineer positions are usually for 2-4 years, with possibilities for extension.\n\n\nWorld-leading research\nWe change the world, together. Weâre a tight-knit team of about 20 PhDâs, postdocs, and engineers working together to create real impact. You can find our work in top AI conferences and journals, including NeurIPS, ICML, CVPR, JMLR, and TPAMI, and we take pride in good engineering and open science, building AI tools used by hundreds of thousands of people.\n\n\nFreedom to Study Deeply and Think Big\nWe donât just follow trends â we set them. We encourage every team member to become a leading expert, think outside the box, and find novel avenues of research. We work on extremey efficient continual and meta-learning inspired by the human brain, we design AI models that design themselves using AutoML, we build platforms and create standards that enable research that wasnât possible before, and even create new venues (e.g.Â NeurIPS Datasets & Benchmarks) to create new incentives and strengthen communities.\n\n\nPurpose-Driven Research\nYour work here will matter. Next to doing transformative fundamental research, we also leverage our insight to tackle real-world problems, in line with AI for good and sustainable development goals.\n\n\nExcellent Career Prospects\nResearch labs and employers around the globe recognize the quality of our researchers, and we collaborate extensively with other leading research labs and organizations all over the world, such as Google, HuggingFace, and MLCommons."
  },
  {
    "objectID": "people/people.html",
    "href": "people/people.html",
    "title": "People",
    "section": "",
    "text": "Permanent researchers\n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Joaquin Vanschoren is an associate professor and head of the Automated Machine Learning lab at TU Eindhoven. He aims to scientifically understand (human-like) intelligence and build AI systems with advanced capabilities for the benefit of all humanity. He authored the first book on AutoML, gave tutorials at NeurIPS and AAAI and won several awards, including the Dutch Data Prize and Amazon Research Award. He founded OpenML, a useful open science platform for machine learning, and co-founded the Croissant standard for sharing AI resources. He was the inaugural chair of the NeurIPS Datasets and Benchmarks track, editor-in-chief of the DMLR journal, and co-chair of the MLCommons AI Risk & Reliability working group. He is a founding member of the European AI societies ELLIS and CAIRNE.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\nResearch engineers\n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Pieter Gijsbers is working on making (automated) machine learning research simple through developing open source software. He is a long-term contributor to openml-python, started the AutoML Benchmark and GAMA. Pieter is currently working on improving the AI-on-Demand platform.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Taniya Das is a Research Engineer solving various engineering and machine learning tasks for openml.org and  AI-on-Demand platform (an EU project), to make ML research better. She has contributed to openml-tensorflowÂ  and openml-pytorchÂ extensions for OpenML, making it possible to use solve deep learning tasks using openml-python API. She is currently working on using LLMs to  make both the platforms more intelligent.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Subhaditya Mukherjee is a Research Engineer working on various engineering and machine learning tasks for openml.org. He is currently working on making the OpenML experience better and more user-friendly.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\nLecturers\n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Prabhant Singh I am currently working as a lecturer and researcher. I have experience in Python, data and systems as well as infrastructure engineering.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\nPostdocs\n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Alexis Cvetkov-Iliev is a postdoc in the group, applying machine-learning techniques to study and optimize building renovation. His research interests include active learning, Bayesian optimization, and transfer learning.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\nPhD students\n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Andrei Simion-Constantinescu is a PhD Researcher in the AutoML group focused on self-supervised learning for computer vision tasks. He holds an MSc degree from TU Delft with the graduation topic on contrastive learning for unlabeled videos. His work involves adapting state-of-the-art self-supervised techniques to solve practical problems in greenhouse crop prediction and vertical farming as part of NWO Sky High Project.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Israel Campero Jurado is a PhD student in computer science working on the European ITEA project called INNO4HEALTH. His interests focus on applying automated machine learning (AutoML) to healthcare solutions and democratising AutoML.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Jiarong Pan is a PhD student in the group, working on improving sample efficiency in machine learning algorithms. His research interests include  meta-learning, Bayesian optimization and multi-objective optimization.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Fangqin Zhou is a PhD student working on the TWINERGY project, which aims to optimize the growth of cherry tomatos in a vertical farm. Her interests focus on the Hyperspectral Imaging using deep learning and transformer models, as well as Reinforcement Learning.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Elif Ceren Gok Yildirim is a PhD student working on continual learning. Her research centers on exploring the capabilities of machine learning algorithms and advancing them to adapt and evolve over time. She likes to explore novel approaches to enable machines to accumulate knowledge from past experiences and apply it to new tasks without forgetting and contribute to the CL field.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Murat Onur Yildirim is a PhD Candidate in the AutoML group. He focuses on automatically and continually learning sparse experts for computer vision tasks. His research is dedicated to creating efficient continual learners by leveraging sparsity in networks, data, and labels.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Bilge Celik is a PhD student focusing on Automated Machine Learning for online data streams. She develops machine learning systems automatically adjusting to changing dynamics of real-time data streams.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\nAlumni and visitors\n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Anna Vettoruzzo received her B.Sc. degree in Information Engineering at the University of Padova, Italy, in 2019, and her M.Sc. degree in ICT for Internet and Multimedia at the University of Padova in 2021, with a focus on Machine Learning for Healthcare. Since 2021, she has been pursuing a Ph.D. degree in the field of machine learning at the School of Information Technology, Halmstad University, Sweden, under the supervision of Assoc. Prof. Mohamed-Rafik Bouguelia and Prof. Thorsteinn RÃ¶gnvaldsson. Her research interests include meta-learning, few-shot learning, continual learning, and, more broadly, enhancing the generalization capabilities of machine learning models.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Branislav Pecher is a former visiting PhD student from Kempelen Institute of Intelligent Technologies. His research mainly focuses on learning with limited labelled data and a better understanding of its sensitivity to different factors that influence how well these approaches work. During the visit, he worked on few-shot learning, exploring how different subsets of samples of different characteristics affect the success of transfer in these approaches, and proposing a new method for selecting a subset of high-quality samples for few-shot learning.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Jos van der Velde is a senior engineer focusing on software architecture and infrastructure. I previously worked on the Croissant standard, and the AI-on-Demand platform. I'm still actively contributing to the OpenML infrastructure.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Mert Kilickaya is a former postdoctoral fellow researching autonomous visual learners that can continuously improve by extracting their own supervision from dynamic visual data streams. He advanced techniques in self-supervised continual learning, enabling AI systems to autonomously adapt and improve without relying on external annotations.\n                        \n                        \n                            \n                            \n                            \n                            \n                        \n                    \n                \n            \n            \n        \n    \n\n\n\n        \n            \n            \n                \n                    \n                        \n                    \n                    \n                        \n                            Rafael Gomes Mantovani is a former PhD student, and currently a professor at the Federal Technology University - ParanÃ¡ (UTFPR), campus of Apucarana, Brazil. He researches Machine Learning, Data Mining, Meta-learning, and Automated Machine Learning/Data Science."
  },
  {
    "objectID": "software/software.html",
    "href": "software/software.html",
    "title": "Software",
    "section": "",
    "text": "This page provides an overview of the software that we built with the goal of transforming the way people do (automated) machine learning research in a way that is more open, reproducible, and accessible. Most of the software below is developed with collaborators outside of our lab.\nWe also open-source the code for our papers under our GitHub organisation. Code for each paper is also linked in the overview in the papers page.\nOpenML\nMachine learning research should be easily accessible and reusable. OpenML is an open platform for sharing datasets, algorithms, and experiments - to learn how to learn better, together.\n\n        \n        Website\n     \n        \n        Github\n    \nAutoML Benchmark\nThe AutoML Benchmark (AMLB) is software that performs end-to-end evaluation of AutoML frameworks. It can be used to compare current state-of-the-art and evaluate new methods with ablation studies. Over 10 AutoML frameworks can be evaluated out-of-the-box on over 100 datasets, and itâs easy to bring your own data or AutoML framework.\n\n        \n        Website\n     \n        \n        Github\n    \nGAMA\nThe General Automated Machine learning Assistant (GAMA) was developed to be able to easily experiment with new AutoML design through ablation studies by providing a modular AutoML framework. We have sunset the project, and decided to focus our efforts on OpenML and AMLB. If you are interested in a modern implementations driven by similar philosophies, please have a look at the AutoML Toolkit.\n\n        \n        Website\n     \n        \n        Github"
  },
  {
    "objectID": "notebooks/amlb-introduction.html",
    "href": "notebooks/amlb-introduction.html",
    "title": "The AutoML Benchmark",
    "section": "",
    "text": "This blogpost is about why we set out to write our paper âAMLB: an AutoML Benchmarkâ (ðpaper, ð¤code) and provides a brief overview of its main contributions. In the end, we will share how you can make an impact on the future of this benchmark and automated machine learning (AutoML). But before we get started, hereâs the tl;dr in haiku form:"
  },
  {
    "objectID": "notebooks/amlb-introduction.html#why-do-we-need-a-standardized-benchmark",
    "href": "notebooks/amlb-introduction.html#why-do-we-need-a-standardized-benchmark",
    "title": "The AutoML Benchmark",
    "section": "Why do we need a standardized benchmark?",
    "text": "Why do we need a standardized benchmark?\nWe started the project back in 2018. Over the summer, I (Pieter Gijsbers) got together with Erin LeDell and Janek Thomas to work on three problems we had identified:\n\nin the field of automated machine learning (in 2018), different papers would rarely evaluate their methods on the same data, and\nresearchers would often make simple âuser errorsâ when evaluating methods proposed by others, and\nthe analyses were almost exclusively focused on predictive performance.\n\nWe decided to address these problems by introducing a benchmark suite, benchmark software, and a multi-dimensional analysis. That initially culminated into an introductory paper at the AutoML Workshop at ICML 2019, and ultimately in our publication at the Journal of Machine Learning Research. Letâs have a closer look at why these problems needed solving and our resulting contributions.\n\nThe Benchmark Suite\nResearch papers evaluating their methods using different sets of data inadvertently means that results are not comparable across different papers. This makes it impossible to determine state-of-the-art or to track progress in the field overtime. It may also lead to accidentally reporting optimistic results. For example, when researchers use a dataset both during development and evaluation, design decisions are made during development which improve performance for that dataset, but it is unlikely that it improves performance for unseen datasets equally. Thus, performance on that dataset is likely optimistic (i.e., better) compared to what you would expect on unseen datasets.\nEven if datasets used in evaluation are not used during development, the researchersâ bias on which type of data they find important, such as biomedical data or big data, may lead to a similar âaccidental cherry pickingâ. That type of data is reasonably assumed to be present during both development and evaluation, and other types of data for which the methods were not developed may be absent also in evaluation. This means that areas where methods may have blind spots are not evaluated and not reported on, giving an incomplete picture of the methodâs strengths and weaknesses.\n\n\n\nHaving a curated set of datasets for evaluation managed by the community and carefully chosen to represent various data domains and characteristics should alleviate these problems. That is why we propose the initial version of such a standardized benchmark suite. The benchmarking suite contains 71 classification and 33 regression datasets that come from many different domains and exhibit many different dataset characteristics. We hope that with a benchmarking suite of this size and variety, we can trust in the generalizability of the results obtained.\n\n\nThe Benchmark Software\nAnother consequence of using a different set of data for each paper is that researchers need to evaluate the methods of others on their data. There are multiple examples where a methodâs performance reported in papers are, for lack of a better word, the result of misunderstandings (or âuser errorsâ). For example, a paper introducing method \\(X\\) and comparing it against state-of-the-art framework \\(Y\\) would report a failure of framework \\(Y\\) on dataset \\(D\\). In several cases we could diagnose the problem that caused the failure of framework \\(Y\\) on dataset \\(D\\) directly from the paper or a few minutes of inspecting the code. Examples would include using an out-of-date release or a wrong configuration of framework \\(Y\\).\n\n\n\nLuckily, as computer scientists, we have a wonderful tool in our belt to reduce human error: automation. Thatâs why we built standardized benchmarking software complete with developer-friendly AutoML framework integrations.\nWith the paper we released our open source benchmarking software. It allows you to run an AutoML evaluation with a single command. A simple python runbenchmark.py autosklearn openml/s/271 1h8c is all you need to evaluate autosklearn on our entire classification benchmark (OpenML suite 271). The software takes care of installing autosklearn, (down)loading the data and providing it to autosklearn, configuring autosklearn with a 1 hour time constraints with a limit of 8 CPU cores (hence 1h8c), monitoring its progress, and processing the predictions of the final model.\nThis level of automation means that no one is accidentally training on a test set. No one accidentally uses different parallelization for different AutoML frameworks, and no one accidentally optimizes for the wrong metrics. Itâs a great step forward for fair comparisons. At least, thatâs the idea. In many cases we make good on the promise, but we are working with a moving target (new framework releases) and bugs happen (see âThe Futureâ below).\nThe way we achieve this is by collaborating with AutoML framework developers. We built a strong shared framework that takes care of bootstrapping the experimental setup. It has generic functionalities for (down)loading data, installing dependencies, keeping track of experiments, processing results, and so on. Then, for each framework we have a minimal integration module which requires an installation script and a Python script which takes as input the data and task description and is expected to produce predictions as output. These integration scripts are often developed by, or in collaboration with, the authors of the AutoML frameworks which significantly reduces the chance that frameworks are used or configured incorrectly.\n\n\nA Multi-Dimensional Analysis\nThe last problem we identified was a single-minded analysis of the results. AutoML frameworks were compared (almost) exclusively on predictive performance. While this is a very important aspect of the final model, it provides an incomplete picture. Depending on the application that the model is trained for, other aspects like fast inference time or interpretability may be important or even required. In those cases, being able to assess the trade-off between predictive performance and other model dimensions is crucial. The characteristics of the AutoML framework itself may also be important: is it robust? is it configurable? does it adhere to resource constraints? Thatâs why we advocate for a multi-dimensional analysis of the results.\n\n\n\nIn our paper we evaluate 9 AutoML frameworks on our benchmarking suite and analyze the results. When analyzing predictive performance, we answer questions like: Which framework ranks best? Is it significant? How does that translate to absolute and relative differences? Do results hold across all data characteristics, or do we see some AutoML frameworks which work particularly well on datasets with certain characteristics?\nBut we also look beyond predictive accuracy. We inspect the learned modelsâ inference time, and discuss its trade-off with predictive performance. We also investigate when AutoML frameworks fail and why: Is it triggered by the data? Is it misuse of resources? Do they adhere to the given time constraints?\nThe experiments in the paper are from 2023, so results would indubitably be different for frameworks today. Bugs are fixed, better methods for building better models are developed. However, we hope the paper serves as an inspiration and example for providing a more thorough multi-dimensional analysis.\n\n\nChallenges and Limitations\nFor more background, examples, challenges, and references you will want to have a look at the paper. It presents ideas presented here in more depth but also includes additional information on e.g., limitations of the benchmark, and it also contains the results and analysis of 9 frameworks on 104 datasets!"
  },
  {
    "objectID": "notebooks/amlb-introduction.html#the-future",
    "href": "notebooks/amlb-introduction.html#the-future",
    "title": "The AutoML Benchmark",
    "section": "The Future",
    "text": "The Future\nOvertime the landscape of data problems changes, as do the capabilities of AutoML frameworks, and the benchmarking suite should be updated to reflect that. One glaring ommission in the benchmark (in my personal opinion) is the lack of text data. In the original benchmarking suite presented in the paper, all datasets have strictly numerical or categorical data. This is for historical reasons, as a significant number of the AutoML frameworks in 2018 did not handle text data natively. But text data is ubiquitous, modern AutoML frameworks are well-equipped to deal with it, so itâs time we reflect that in the benchmark.\nMoreover, there is nothing uniquely âAutoMLâ about the AutoML benchmark. It benchmarks anything for which you write an integration script that takes as input a task and constraint description, and provides predictions as output. Sure, many algorithms may not deal with various dataset characteristics out-of-the-box (e.g., text data may need to be encoded) and the method may not adhere to time constraints, but that doesnât mean the software can provide much of the same benefits of automation to evaluating âregularâ ML algorithms (in fact, TabRepo used AMLB). We hope to explore this further and potentially position AMLB for more general tabular ML benchmarking.\nAnd last but not least, though perhaps not as sexy, is the brunt of software engineering work. As time goes on, AutoML frameworks have new releases, people use different hardware, and AutoML is used for new problems, which means we are always working with a moving target. The benchmarking software needs to be maintained to work with modern stacks, extended to allow evaluation of different problem types, and incidental bugs need to be squashed. On top of that, we are continuously exploring ways to make the software easier to use for both developers and researchers.\nThe benchmark isnât perfect, or even finished. Itâs a start. And we invite you to collaborate with us.\nThere are many ways to contribute. The easiest way is to help is to leave a â­ï¸ on our GitHub project, talk about the AutoML benchmark, and use it in your work. There are also a number of no-code contributions that help us out greatly:\n\nð¤ Help people on our GitHub issue tracker\nð Improve our documentation\nð¤ Identify interesting new datasets\n\nAnd finally, we very much welcome code contributions. ð§âð»\n\nThis post was written by Pieter Gijsbers and need not reflect the view of co-authors."
  },
  {
    "objectID": "publications/publications.html",
    "href": "publications/publications.html",
    "title": "Publications",
    "section": "",
    "text": "2024\nAMLB: An AutoML BenchmarkP. Gijsbers, M. L. P. Bueno, S. Coors, E. LeDell, S. Poirier, J. Thomas, B. Bischl, and J. VanschorenJournal of Machine Learning Research, 25 (101), 1--65 (2024)\n        \n        PDF\n     \n        \n        Github\n     \n        \n        Published\n    \nTowards Efficient AutoML: A Pipeline Synthesis Approach Leveraging Pre-Trained Transformers for Multimodal DataA. Moharil, J. Vanschoren, P. Singh, and D. TamburriMachine Learning, 113, 7011â7053 (2024)\n        \n        PDF\n     \n        \n        Published\n    \nAdvances and Challenges in Meta-Learning: A Technical ReviewA. Vettoruzzo, M.-R. Bouguelia, J. Vanschoren, T. Rognvaldsson, and K. C. SantoshIEEE Transactions on Pattern Analysis and Machine Intelligence (2024)\n        \n        Published\n    \nCan Fairness Be Automated? Guidelines and Opportunities for Fairness-Aware AutoMLH. Weerts, F. Pfisterer, M. Feurer, K. Eggensperger, E. Bergman, N. Awad, J. Vanschoren, M. Pechenizkiy, B. Bischl, and F. HutterJournal of Artificial Intelligence Research, 79, 639--677 (2024)\n        \n        Published\n    \nCroissant: A Metadata Format for ML-Ready DatasetsM. Akhtar, O. Benjelloun, C. Conforti, P. Gijsbers, J. Giner-Miguelez, N. Jain, M. Kuchnik, Q. Lhoest, P. Marcenac, M. Maskey, P. Mattson, L. Oala, P. Ruyssen, R. Shinde, E. Simperl, G. Thomas, S. Tykhonov, J. Vanschoren, J. van der Velde, S. Vogler, and C.-J. WuAdvances in Neural Information Processing Systems (NeurIPS 2024) (2024)\n        \n        Published\n    \nTrustLLM: Trustworthiness in Large Language ModelsY. Huang, L. Sun, H. Wang, and others, and J. VanschorenInternational Conference on Machine Learning (ICML 2024), 20166--20270 (2024)\n        \n        Published\n    \nMALIBO: Meta-Learning for Likelihood-Free Bayesian OptimizationJ. Pan, S. Falkner, F. Berkenkamp, and J. VanschorenInternational Conference on Machine Learning (ICML 2024) (2024)\n        \n        PDF\n     \n        \n        Github\n     \n        \n        Published\n    \nLearning to Learn without Forgetting Using AttentionA. Vettoruzzo, J. Vanschoren, M.-R. Bouguelia, and T. RÃ¶gnvaldssonConference on Lifelong Learning Agents (CoLLAs 2024) (2024)\n        \n        PDF\n     \n        \n        Published\n    \nContinual Learning with Dynamic Sparse Training: Exploring Algorithms for Effective Model UpdatesM. O. Yildirim, E. C. Gok, G. Sokar, D. C. Mocanu, and J. VanschorenConference on Parsimony and Learning (CPAL 2024), 94--107 (2024)\n        \n        Published\n    \nHyTAS: A Hyperspectral Image Transformer Architecture Search Benchmark and AnalysisF. Zhou, M. Kilickaya, J. Vanschoren, and R. PiaoEuropean Conference on Computer Vision (ECCV 2024) (2024)\n        \n        PDF\n     \n        \n        Github\n     \n        \n        Published\n    \nCroissant: A Metadata Format for ML-Ready DatasetsM. Akhtar, O. Benjelloun, C. Conforti, P. Gijsbers, J. Giner-Miguelez, N. Jain, M. Kuchnik, Q. Lhoest, P. Marcenac, M. Maskey, P. Mattson, L. Oala, P. Ruyssen, R. Shinde, E. Simperl, G. Thomas, V. Tykhonov, J. Vanschoren, S. Vogler, and C.-J. WuSIGMOD/PODS Workshop on Data Management for End-to-End Machine Learning (DEEM 2024), 1--6 (2024)\n        \n        Published\n    \nInternational Conference on Automated Machine LearningM. Lindauer, K. Eggensperger, R. Garnett, and J. VanschorenProceedings of Machine Learning Research, Volume 256, PMLR, 2024 (2024)\n        \n        Published\n    \nA Standardized Machine-Readable Dataset Documentation Format for Responsible AIN. Jain, M. Akhtar, J. Giner-Miguelez, R. Shinde, J. Vanschoren, S. Vogler, S. Goswami, Y. Rao, T. Santos, and L. OalaarXiv preprint arXiv:2407.16883, 2024 (2024)\n        \n        Preprint\n    \nAutomatic Combination of Sample Selection Strategies for Few-Shot LearningB. Pecher, I. Srba, M. Bielikova, and J. VanschorenarXiv preprint arXiv:2402.03038, 2024 (2024)\n        \n        Preprint\n    \nCLAMS: A System for Zero-Shot Model Selection for ClusteringP. Singh, P. Gijsbers, M. O. Yildirim, E. C. Gok, and J. VanschorenarXiv preprint arXiv:2407.11286, 2024 (2024)\n        \n        Preprint\n    \nRobust and Efficient Transfer Learning via Supernet Transfer in Warm-Started Neural Architecture SearchP. Singh and J. VanschorenarXiv preprint arXiv:2407.20279, 2024 (2024)\n        \n        Preprint\n    \nCan Time Series Forecasting Be Automated? A Benchmark and AnalysisA. T. Sreedhara and J. VanschorenarXiv preprint arXiv:2407.16445, 2024 (2024)\n        \n        Preprint\n    \nUnsupervised Meta-Learning via In-Context LearningA. Vettoruzzo, L. Braccaioli, J. Vanschoren, and M. NowaczykarXiv preprint arXiv:2405.16124, 2024 (2024)\n        \n        Preprint\n    \nIntroducing v0.5 of the AI Safety Benchmark from MLCommonsB. Vidgen, A. Agrawal, A. M. Ahmed, V. Akinwande, N. Al-Nuaimi, N. Alfaraj, E. Alhajjar, L. Aroyo, T. Bavalatti, B. Blili-Hamelin, and J. VanschorenarXiv preprint arXiv:2404.12241, 2024 (2024)\n        \n        Preprint\n    \nContinual Learning on a Data DietE. C. Gok Yildirim, M. O. Yildirim, and J. VanschorenarXiv preprint arXiv:2410.17715, 2024 (2024)\n        \n        Preprint\n    \nFOCIL: Finetune-and-Freeze for Online Class Incremental Learning by Training Randomly Pruned Sparse ExpertsM. O. Yildirim, E. C. Gok Yildirim, D. C. Mocanu, and J. VanschorenarXiv preprint arXiv:2403.14684, 2024 (2024)\n        \n        Preprint\n    \n2023\nSignal Quality Analysis for Long-Term ECG Monitoring Using a Health Patch in Cardiac PatientsI. Campero Jurado, I. Lorato, J. Morales, L. Fruytier, S. Stuart, P. Panditha, D. M. Janssen, N. Rossetti, N. Uzunbajakava, I. B. Serban, L. Rikken, M. de Kok, J. Vanschoren, and A. BrombacherSensors, 23 (4), Art. 2130 (2023)\n        \n        Published\n    \nOnline AutoML: An Adaptive AutoML Framework for Online LearningB. Celik, P. Singh, and J. VanschorenMachine Learning, 112 (6), 1897--1921 (2023)\n        \n        Published\n    \nAutomated Machine Learning Approach in Material Discovery of Hole Selective Layers for Perovskite Solar CellsM. O. Yildirim, E. C. Gok Yildirim, E. Eren, P. Huang, M. P. U. Haris, S. Kazim, J. Vanschoren, A. Uygun Oksuz, and S. AhmadEnergy Technology, 11 (1) (2023)\n        \n        Published\n    \nEfficient-DASH: Automated Radar Neural Network Design Across Tasks and DatasetsT. Boot, N. Cazin, W. Sanberg, and J. VanschorenIEEE Intelligent Vehicles Symposium (IV 2023), 1--7 (2023)\n        \n        Published\n    \nAn Analysis of Evolutionary Migration Models for Multi-Objective, Multi-Fidelity AutoMLI. Campero-Jurado and J. VanschorenIEEE International Conference on Systems, Man, and Cybernetics (SMC 2023), 2940--2945 (2023)\n        \n        Published\n    \nNeural Architecture Search for Visual Anomaly SegmentationT. Kerssies and J. VanschorenAutoML Conference (AutoML 2023) (2023)\n        \n        Published\n    \nAre Labels Needed for Incremental Instance Learning?M. Kilickaya and J. VanschorenIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2023), 2401--2409 (2023)\n        \n        Published\n    \nDataperf: Benchmarks for Data-Centric AI DevelopmentM. Mazumder, C. Banbury, X. Yao, and others, and J. VanschorenAdvances in Neural Information Processing Systems (NeurIPS 2023) (2023)\n        \n        Published\n    \nAutoML for Outlier Detection with Optimal Transport DistancesP. Singh and J. VanschorenProceedings of the Thirty-Second International Joint Conference on Artificial Intelligence (IJCAI 2023), 7175--7178 (2023)\n        \n        Published\n    \nAdaCL: Adaptive Continual LearningE. C. Gok Yildirim, M. O. Yildirim, M. Kilickaya, and J. VanschorenContinual AI Unconference (ContinualAI 2024), PMLR, 249, 15--24 (2023)\n        \n        Published\n    \nLocality-Aware Hyperspectral ClassificationF. Zhou, M. Kilickaya, and J. VanschorenThe British Machine Vision Conference (BMVC 2023) (2023)\n        \n        Published\n    \nNeurIPSâ22 Cross-Domain MetaDL Challenge: Results and Lessons LearnedD. CarriÃ³n-Ojeda, M. Alam, S. Escalera, A. Farahat, D. Ghosh, T. G. Diaz, C. Gupta, I. Guyon, J. R. Ky, X. Y. Lee, X. Liu, F. Mohr, M. H. Nguyen, E. Pintelas, S. Roth, S. Schaub-Meyer, H. Sun, I. Ullah, J. Vanschoren, L. Vidyaratne, J. Wu, and X. YinNeurIPS 2022 Competition Track, 50--72 (2023)\n        \n        Published\n    \nDemocratising Artificial Intelligence to Accelerate Scientific DiscoveryJ. VanschorenIn: Artificial Intelligence in Science, OECD, 2023 (2023)\n        \n        Published\n    \nEvaluating Continual Test-Time Adaptation for Contextual and Semantic Domain ShiftsT. Kerssies, M. KÄ±lÄ±Ã§kaya, and J. VanschorenarXiv preprint arXiv:2208.08767, 2023 (2023)\n        \n        Preprint\n    \nWhat Can AutoML Do for Continual Learning?M. KÄ±lÄ±Ã§kaya and J. VanschorenarXiv preprint arXiv:2311.11963, 2023 (2023)\n        \n        Preprint\n    \nDMLR: Data-Centric Machine Learning Research -- Past, Present and FutureL. Oala, M. Maskey, L. Bat-Leah, A. Parrish, N. M. GÃ¼rel, T.-S. Kuo, Y. Liu, R. Dror, D. Brajovic, X. Yao, and J. VanschorenarXiv preprint arXiv:2311.13028, 2023 (2023)\n        \n        Preprint\n    \n2022\nAgroML: An Open-Source Repository to Forecast Reference Evapotranspiration in Different Geo-Climatic Conditions Using Machine Learning and Transformer-Based ModelsJ. A. Bellido-JimÃ©nez, J. EstÃ©vez, J. Vanschoren, and A. P. GarcÃ­a-MarÃ­nAgronomy, 12 (3), 656 (2022)\n        \n        Published\n    \nInterpretable Assessment of ST-Segment Deviation in ECG Time SeriesI. Campero Jurado, A. Fedjajevs, J. Vanschoren, and A. BrombacherSensors, 22 (13), Art. 4919 (2022)\n        \n        Published\n    \nMeta-Features for Meta-LearningA. Rivolli, L. P. F. Garcia, C. Soares, J. Vanschoren, and A. C. P. L. F. de CarvalhoKnowledge-Based Systems, 240, 108101 (2022)\n        \n        Published\n    \nTheory-Based Habit Modeling for Enhancing Behavior Prediction in Behavior Change Support SystemsC. Zhang, J. Vanschoren, A. van Wissen, D. Lakens, B. de Ruyter, and W. A. IJsselsteijnUser Modeling and User-Adapted Interaction, 23 (2022)\n        \n        Published\n    \nMulti-Fidelity Optimization Method with Asynchronous Generalized Island Model for AutoMLI. Campero-Jurado and J. VanschorenGenetic and Evolutionary Computation Conference (GECCO 2022) (2022)\n        \n        Published\n    \nMeta-Album: Multi-Domain Meta-Dataset for Few-Shot Image ClassificationI. Ullah, D. CarriÃ³n-Ojeda, S. Escalera, I. Guyon, M. Huisman, F. Mohr, J. N. van Rijn, H. Sun, J. Vanschoren, and P. A. VuAdvances in Neural Information Processing Systems 35 (NeurIPS 2022), 3232--3247 (2022)\n        \n        Published\n    \nRegularized Meta-Learning for Neural Architecture SearchR. van Gastel and J. VanschorenAutomated Machine Learning Conference (AutoML 2022) (2022)\n        \n        Published\n    \nFaster Performance Estimation for NAS with Embedding Proximity ScoreG. Franken, P. Singh, and J. VanschorenECMLPKDD Workshop on Meta-Knowledge Transfer, PMLR, 51--61 (2022)\n        \n        Published\n    \nIntroduction to the Special Section on AI in Manufacturing: Current Trends and ChallengesJ. Lijffijt, D. Gkorou, P. Van Hertum, A. Ypma, M. Pechenizkiy, and J. VanschorenACM SIGKDD Explorations Newsletter, 24 (2), 81--85 (2022)\n        \n        Published\n    \nMetalearning: Applications to Automated Machine Learning and Data MiningP. Brazdil, J. N. van Rijn, C. Soares, and J. VanschorenSpringer Nature, 2022 (2022)\n        \n        Published\n    \nAutomated Reinforcement Learning: An OverviewR. R. Afshar, Y. Zhang, J. Vanschoren, and U. KaymakarXiv preprint arXiv:2201.05000, 2022 (2022)\n        \n        Preprint\n    \nWarm-starting DARTS Using Meta-LearningM. Grobelnik and J. VanschorenarXiv preprint arXiv:2205.06355, 2022 (2022)\n        \n        Preprint\n    \n2021\nA Comparison of Optimisation Algorithms for High-Dimensional Particle and Astrophysics ApplicationsC. BalÃ¡zs, M. van Beekveld, S. Caron, B. M. Dillon, B. Farmer, A. Fowlie, W. Handley, L. Hendriks, G. JÃ³hannesson, A. Leinweber, J. MamuÅ¾iÄ, G. D. Martinez, P. Scott, E. C. Garrido-MerchÃ¡n, R. Ruiz de Austri, Z. Searle, B. Stienen, J. Vanschoren, and M. WhiteJournal of High Energy Physics, 2021 (5), 1â46 (2021)\n        \n        Published\n    \nAdaptation Strategies for Automated Machine Learning on Evolving DataB. Celik and J. VanschorenIEEE Transactions on Pattern Analysis and Machine Intelligence, 43 (9) (2021)\n        \n        Published\n    \nOpenML-Python: An Extensible Python API for OpenMLM. Feurer, J. N. van Rijn, A. Kadra, P. Gijsbers, N. Mallik, S. Ravi, A. Mueller, J. Vanschoren, and F. HutterJournal of Machine Learning Research, 22 (100), 1â5 (2021)\n        \n        Github\n     \n        \n        Published\n    \nTransformational Machine Learning: Learning How to Learn from Many Related Scientific ProblemsI. Olier, I. O. Oghenejokpeme, T. Dash, A. Davis, L. N. Soldatova, J. Vanschoren, and R. D. KingProceedings of the National Academy of Sciences (PNAS), 118 (49) (2021)\n        \n        Published\n    \nOpenML Benchmarking SuitesB. Bischl, G. Casalicchio, M. Feurer, F. Hutter, M. Lang, R. G. Mantovani, J. N. van Rijn, and J. VanschorenProceedings of the NeurIPS Track on Datasets and Benchmarks 2021 (2021)\n        \n        Published\n    \nMeta-Learning for Symbolic Hyperparameter DefaultsP. Gijsbers, F. Pfisterer, J. N. van Rijn, B. Bischl, and J. VanschorenGenetic and Evolutionary Computation Conference (GECCO) Companion, 2021 (2021)\n        \n        Github\n     \n        \n        Published\n    \nGAMA: A General Automated Machine Learning AssistantP. Gijsbers and J. VanschorenProceedings of ECMLPKDD 2021. Lecture Notes in Computer Science, 12461 (2021), p560-564 (2021)\n        \n        Github\n     \n        \n        Published\n    \nAdvances in MetaDL: AAAI 2021 Challenge and WorkshopA. E. Baz, I. Guyon, Z. Liu, J. van Rijn, S. Treguer, and J. VanschorenAAAI 2021 Workshop on Meta-Learning and MetaDL, PMLR 140:1--16 (2021)\n        \n        Published\n    \nVariational Task Encoders for Model-Agnostic Meta-Learning with Uncertainty Over Task DistributionsL. Schragen and J. VanschorenWorkshop on Meta-Learning @ NeurIPS 2021 (2021)\n        \n        Published\n    \nFrom Strings to Data Science: A Practical Framework for Automated String HandlingJ. van Lith and J. VanschorenWorkshop on Automated Data Science @ ECMLPKDD 2021 (2021)\n        \n        Published\n    \nOpen-Ended Learning Strategies for Learning Complex Locomotion SkillsF. Zhou and J. VanschorenWorkshop on Meta-Learning @ NeurIPS 2021 (2021)\n        \n        Published\n    \nProceedings of the Neural Information Processing Systems Track on Datasets and BenchmarksJ. Vanschoren and S. YeungNeurIPS Foundation, Curran Associates, 2021 (2021)\n        \n        Published\n    \nProceedings of the AAAI 2021 Workshop on Meta-Learning and MetaDL ChallengeI. Guyon, J. N. van Rijn, S. Treguer, and J. VanschorenPMLR, 2021 (2021)\n        \n        Published\n    \nAutomated Feature Selection and Classification for High-Dimensional Biomedical DataT. P. Beishuizen, J. Vanschoren, P. A. Hilbers, and D. BoÅ¡naÄkiResearchSquare, 2021 (2021)\n        \n        Published\n    \nCats, Not CAT Scans: A Study of Dataset Similarity in Transfer Learning for 2D Medical Image ClassificationI. van den Brandt, F. Fok, B. Mulders, J. Vanschoren, and V. CheplyginaarXiv preprint arXiv:2107.05940, 2021 (2021)\n        \n        Preprint\n    \nFrugal Machine LearningM. Evchenko, J. Vanschoren, H. H. Hoos, M. Schoenauer, and M. SebagarXiv preprint arXiv:2111.03731, 2021 (2021)\n        \n        Preprint\n    \nFixed-Point Quantization of Convolutional Neural Networks for Quantized Inference on Embedded PlatformsR. Goyal, J. Vanschoren, V. Van Acht, and S. NijssenarXiv preprint arXiv:2102.02147, 2021 (2021)\n        \n        Preprint\n    \n2020\nAerial Imagery Pixel-Level SegmentationM. R. Heffels and J. VanschorenarXiv preprint arXiv:2012.02024, 2020 (2020)\n        \n        Preprint\n    \nImportance of Tuning Hyperparameters of Machine Learning AlgorithmsH. Weerts, A. Mueller, and J. VanschorenarXiv preprint arXiv:2007.07588, 2020 (2020)\n        \n        Preprint\n    \n2019\nGAMA: Genetic Automated Machine Learning AssistantP. Gijsbers and J. VanschorenJournal of Open Source Software, 4 (33), 1â2 (2019)\n        \n        Github\n     \n        \n        Published\n    \nA Meta-Learning Recommender System for Hyperparameter Tuning: Predicting When Tuning Improves SVM ClassifiersR. G. Mantovani, A. L. D. Rossi, E. Alcobaca, J. Vanschoren, and A. C. P. L. F. CarvalhoInformation Sciences, 501, 193â221 (2019)\n        \n        Published\n    \nMulti-Task Learning with a Natural Metric for Quantitative Structure Activity Relationship LearningN. Sadawi, I. Olier, J. Vanschoren, J. N. van Rijn, J. Besnard, R. Bickerton, C. Grosan, L. Soldatova, and R. D. KingJournal of Cheminformatics, 11 (1), Art. 68 (2019)\n        \n        Published\n    \nBeyond Bag-of-Concepts: Vectors of Locally Aggregated ConceptsM. Grootendorst and J. VanschorenProceedings of ECMLPKDD 2019 (2019)\n        \n        Published\n    \nThe ABC of Data: A Classifying Framework for Data ReadinessL. A. Castelijns, Y. Maas, and J. VanschorenWorkshop on Automating Data Science @ ECMLPKDD 2019 (2019)\n        \n        Published\n    \nLearning to Go with the Flow: On the Adaptability of Automated Machine Learning to Evolving DataB. Celik and J. VanschorenWorkshop on Automating Data Science @ ECMLPKDD 2019 (2019)\n        \n        Published\n    \nAn Open Source AutoML BenchmarkP. Gijsbers, E. Ledell, J. Thomas, S. Poirier, B. Bischl, and J. VanschorenAutomated Machine Learning Workshop @ ICML 2019 (2019)\n        \n        Published\n    \nMeta-Learning for Algorithm and Hyperparameter Optimization with Surrogate Model EnsemblesG. Manolache and J. VanschorenMeta-Learning Workshop @ NeurIPS 2019 (2019)\n        \n        Published\n    \nLearning to Reinforcement Learn for Neural Architecture SearchJ. Robles and J. VanschorenNew in ML Symposium @ NeurIPS 2019 (2019)\n        \n        Published\n    \nHyperBoost: Hyperparameter Optimization by Gradient Boosting Surrogate ModelsJ. van Hoof and J. VanschorenWorkshop on Automating Data Science @ ECMLPKDD 2019 (2019)\n        \n        Published\n    \nMeta-LearningJ. VanschorenIn: Automatic Machine Learning: Methods, Systems, Challenges. Springer, 2019 (2019)\n        \n        Published\n    \nAutomatic Machine Learning: Methods, Systems, ChallengesF. Hutter, L. Kotthoff, and J. VanschorenSpringer, 2019 (2019)\n        \n        Published\n    \nMLSys: The New Frontier of Machine Learning SystemsA. Ratner, J. Vanschoren, and and othersarXiv preprint arXiv:1904.03257, 2019 (2019)\n        \n        Preprint\n    \n2018\nSpeeding Up Algorithm Selection via Meta-Learning and Active TestingS. Abdulrahman, P. Brazdil, J. N. van Rijn, and J. VanschorenMachine Learning, 107 (1), 79â108 (2018)\n        \n        Published\n    \nMeta-QSAR: Learning How to Learn QSARsI. Olier, N. Sadawi, G. R. Bickerton, J. Vanschoren, C. Grosan, L. Soldatova, and R. D. KingMachine Learning, 107 (1), 285â311 (2018)\n        \n        Published\n    \nThe Online Performance Estimation Framework: Heterogeneous Ensemble Learning for Data StreamsJ. N. van Rijn, G. Holmes, B. Pfahringer, and J. VanschorenMachine Learning, 107 (1), 149â176 (2018)\n        \n        Published\n    \nML Schema: Exposing the Semantics of Machine Learning with Schemas and OntologiesG. Correa Publio, D. Esteves, A. Åawrynowicz, P. Panov, L. Soldatova, T. Soru, J. Vanschoren, and H. ZafarICML 2018 Workshop on Reproducibility in Machine Learning (2018)\n        \n        Published\n    \nMeta Learning for Defaults: Symbolic DefaultsJ. N. van Rijn, F. Pfisterer, J. Thomas, A. Mueller, B. Bischl, and J. VanschorenMeta-Learning Workshop @ NeurIPS 2018 (2018)\n        \n        Published\n    \nData Augmentation Using Conditional Generative Adversarial Networks for Leaf Counting in Arabidopsis PlantsY. Zhu, M. Aoun, M. Krijn, and J. VanschorenCCCPV Workshop @ BMVC 2018 (2018)\n        \n        Published\n    \nProceedings of the 21st International Conference on Discovery ScienceL. Soldatova, J. Vanschoren, G. Papadopoulos, and M. CeciLecture Notes in Artificial Intelligence 11198, DS 2018 (2018)\n        \n        Published\n    \nMetalearning: A SurveyJ. VanschorenarXiv preprint arXiv:1810.03548, 2018 (2018)\n        \n        Preprint\n    \nTowards Reproducible Empirical Research in Meta-LearningA. Rivolli, L. Garcia, C. Soares, J. Vanschoren, and A. C. de CarvalhoarXiv preprint arXiv:1808.10406, 2018 (2018)\n        \n        Preprint\n    \n2017\nOpenML: An R Package to Connect to the Networked Machine Learning PlatformG. Casalicchio, B. Hofner, M. Lang, D. Kirchhoff, P. Kerschke, H. Seibold, J. Bossek, J. Vanschoren, and B. BischlComputational Statistics, 32 (3), 1â15 (2017)\n        \n        Published\n    \nLayered TPOT: Speeding Up Tree-Based Pipeline OptimizationP. Gijsbers, J. Vanschoren, and R. OlsonAutoML Workshop @ ECML 2017, CEUR Workshop Proceedings vol. 1998 (2017)\n        \n        Published\n    \nProceedings of the Twenty-Sixth Benelux Conference on Machine LearningW. Duivesteijn, M. Pechenizkiy, G. H. L. Fletcher, V. Menkovski, E. J. Postma, and J. VanschorenEindhoven University of Technology Eindhoven, 2017 (2017)\n        \n        Published\n    \n2016\nAn Algorithm, Implementation and Execution Ontology Design PatternA. Lawrynowicz, D. Esteves, P. Panov, T. Soru, S. Dzeroski, and J. VanschorenIn: Studies on the Semantic Web (Hitzler.P., Gangemi, A., Janowicz, K., Krisnadhi, A., Presutti, V., eds.), IOS Press (2016)\n        \n        Published\n    \nASlib: A Benchmark Library for Algorithm SelectionB. Bischl, P. Kerschke, L. Kotthoff, M. Lindauer, Y. Malitsky, A. Frechette, H. Hoos, F. Hutter, K. Leyton-Brown, K. Tierney, and J. VanschorenArtificial Intelligence, 237, 41â58 (2016)\n        \n        Published\n    \nReduction of False Arrhythmia Alarms Using Signal Selection and Machine LearningL. M. Eerikainen, J. Vanschoren, M. J. Rooijakkers, R. Vullings, and R. M. AartsPhysiological Measurement, 37 (8), 1204â1216 (2016)\n        \n        Published\n    \nTowards Understanding Online Sentiment Expression: An Interdisciplinary Approach with Subgroup Comparison and VisualizationB. Gao, B. Berendt, and J. VanschorenSocial Network Analysis and Mining, 6 (1), 68:1â68:16 (2016)\n        \n        Published\n    \nConnecting R to the OpenML Project for Open Machine LearningB. Bischl, G. Casalicchio, B. Hofner, P. Kerschke, D. Kirchhoff, M. Lang, H. Seibold, and J. VanschorenUseR! Conference (UseR 2016), 1--11 (2016)\n        \n        Published\n    \nAnticipating Habit Formation: A Psychological Computing Approach to Behavior Change SupportC. Zhang, A. van Wissen, D. Lakens, J. Vanschoren, B. De Ruyter, and W. A. IJsselsteijnProceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2016), 1247--1254 (2016)\n        \n        Published\n    \nHyper-Parameter Tuning of a Decision Tree Induction AlgorithmR. G. Mantovani, T. Horvath, R. Cerri, A. P. L. F. Carvalho, and J. VanschorenBrazilian Conference on Intelligent Systems (BRACIS 2016) (2016)\n        \n        Published\n    \nProceedings of the 10th International Conference on Learning and Intelligent OptimizationP. Festa, M. Sellmann, and J. VanschorenLecture Notes in Computer Science 10079, LION 2016 (2016)\n        \n        Published\n    \nProceedings of the ICML 2016 Workshop on Automatic Machine LearningF. Hutter, L. Kotthoff, and J. VanschorenPMLR, 2016 (2016)\n        \n        Published\n    \n2015\nDecreasing the False Alarm Rate of Arrhythmias in Intensive Care Using a Machine Learning ApproachL. M. Eerikainen, J. Vanschoren, M. J. Rooijakkers, R. Vullings, and R. M. AartsIEEE Computing in Cardiology, 42, 293-297 (2015)\n        \n        Published\n    \nWho is More Positive in Private? Analyzing Sentiment Differences Across Privacy Levels and Demographic Factors in Facebook Chats and PostsB. Gao, B. Berendt, and J. VanschorenIEEE/ACM Proceedings of ASONAM 2015, 605-610 (2015)\n        \n        Published\n    \nTo Tune or Not to Tune: Recommending When to Adjust SVM Hyper-Parameters via Meta-LearningR. G. Mantovani, A. L. D. Rossi, J. Vanschoren, B. Bischl, and A. C. P. L. F. CarvalhoIEEE Proceedings of IJCNN 2015, 1-8 (2015)\n        \n        Published\n    \nEffectiveness of Random Search in SVM Hyper-Parameter TuningR. G. Mantovani, A. L. D. Rossi, J. Vanschoren, B. Bischl, and A. C. P. L. F. CarvalhoIEEE Proceedings of IJCNN 2015, 1-8 (2015)\n        \n        Published\n    \nFast Algorithm Selection Using Learning CurvesJ. N. van Rijn, S. M. Abdulrahman, P. Brazdil, and J. VanschorenAdvances in Intelligent Data Analysis XIV (IDA 2015), Lecture Notes in Computer Science 9385, 298-309 (2015)\n        \n        Published\n    \nTowards a Data Science CollaboratoryJ. Vanschoren, B. Bischl, F. Hutter, M. Sebag, B. Kegl, M. Schmid, G. Napolitano, K. Wolstencroft, A. R. Williams, and N. LawrenceAdvances in Intelligent Data Analysis XIV (IDA 2015), Lecture Notes in Computer Science 9385, XIX-XXI (2015)\n        \n        Published\n    \nAlgorithm Selection via Meta-Learning and Sample-Based Active TestingS. Abdulrahman, P. Brazdil, J. N. van Rijn, and J. VanschorenMetaSel Workshop @ PKDD/ECML 2015, CEUR Workshop Proceedings 1455, 55-66 (2015)\n        \n        Published\n    \nMeta-Learning Recommendation of Default Hyper-Parameter Values for SVMs in Classification TasksR. G. Mantovani, A. L. D. Rossi, J. Vanschoren, and A. C. P. L. F. CarvalhoMetaSel Workshop @ PKDD/ECML 2015, CEUR Workshop Proceedings 1455, 80-92 (2015)\n        \n        Published\n    \nSharing RapidMiner Workflows and Experiments with OpenMLJ. N. van Rijn and J. VanschorenMetaSel Workshop @ PKDD/ECML 2015, CEUR Workshop Proceedings 1455, 93-103 (2015)\n        \n        Published\n    \nTaking Machine Learning Research Online with OpenMLJ. Vanschoren, J. N. van Rijn, and B. BischlJMLR Workshop and Conference Proceedings (BigMine 2015), 41, 1-4 (2015)\n        \n        Published\n    \nTowards a Collaborative Platform for Advanced Meta-Learning in Healthcare Predictive AnalyticsM. Vukicevic, S. Radovanovic, J. Vanschoren, G. Napolitano, and B. DelibasicMetaSel Workshop @ PKDD/ECML 2015, CEUR Workshop Proceedings 1455, 112-114 (2015)\n        \n        Published\n    \nProceedings of the 2015 International Workshop on Meta-Learning and Algorithm Selection @ ECMLPKDDJ. Vanschoren, P. Brazdil, C. G. Giraud-Carrier, and L. KotthoffCEUR Workshop Proceedings 1455, CEUR 2015 (2015)\n        \n        Published\n    \n2014\nOpenML: Networked Science in Machine LearningJoaquin Vanschoren, Jan N. van Rijn, Bernd Bischl, and Luis TorgoACM SIGKDD Explorations Newsletter (2014)\n        \n        Preprint\n     \n        \n        Github\n     \n        \n        Published\n    \nTowards Meta-Learning on Data StreamsJ. N. van Rijn, G. Holmes, B. Pfahringer, and J. VanschorenMetaSel Workshop @ ECAI 2014, CEUR Workshop Proceedings 1201, 37-38 (2014)\n        \n        Published\n    \nAlgorithm Selection on Data StreamsJ. N. van Rijn, G. Holmes, B. Pfahringer, and J. VanschorenProceedings of Discovery Science 2014, Lecture Notes in Computer Science 8777, 325-336 (2014)\n        \n        Published\n    \nProceedings of the 2014 International Workshop on Meta-Learning and Algorithm Selection @ ECAIJ. Vanschoren, P. Brazdil, and L. KotthoffCEUR Workshop Proceedings 1201, CEUR 2014 (2014)\n        \n        Published\n    \nReconstructing Medieval Social Networks from English and Latin ChartersA. J. Knobbe, M. Meeng, J. Vanschoren, S. Rees Jones, and S. Merlo PenningPopulation Reconstruction 2014 (2014)\n        \n        Published\n    \n2013\nA Survey of Intelligent Assistants for Data AnalysisF. Serban, J. Vanschoren, J. U. Kietz, and A. BernsteinACM Computing Surveys, 45 (3), Art. 31 (2013)\n        \n        Published\n    \nA RapidMiner Extension for Open Machine LearningJ. N. van Rijn, V. Umaashankar, S. Fischer, B. Bischl, T. Lorgo, B. Gao, P. Winter, B. Wiswedel, M. R. Berthold, and J. VanschorenProceedings of RCOMM 2013, 59-70 (2013)\n        \n        Published\n    \n2012\nExperiment Databases: A New Way to Share, Organize and Learn from ExperimentsJ. Vanschoren, H. Blockeel, B. Pfahringer, and G. HolmesMachine Learning, 87 (2), 127â158 (2012)\n        \n        Published"
  }
]