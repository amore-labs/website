{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0094bb47",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Self-Regulated Neurogenesis for Online Data-Incremental Learning\n",
    "topic: Method\n",
    "author: Murat Onur Yildirim\n",
    "date: 2025-06-04\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "image: serena/teaser.webp \n",
    "preview: A blogpost based on our paper \"SERENA\" proposing a neuro-inspired solution for continual learning.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0706f",
   "metadata": {},
   "source": [
    "# Self-Regulated Neurogenesis for Online Data-Incremental Learning\n",
    "[Murat Onur Yildirim](https://muratonuryildirim.github.io/), [Elif Ceren Gok Yildirim](https://elifcerengokyildirim.github.io/), [Decebal Constantin Mocanu](https://scholar.google.nl/citations?user=RlQgUwEAAAAJ&hl=en), [Joaquin Vanschoren](https://joaquinvanschoren.github.io/home/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1021c5f2",
   "metadata": {},
   "source": [
    "**TL;DR:** This blog post dives into our recent paper \"Self-Regulated Neurogenesis for Online Data-Incremental Learning\" (üìÑ [Paper](https://arxiv.org/abs/2403.14684), ü§ñ [Code](https://github.com/muratonuryildirim/serena)) published in CoLLAs 2025. SERENA is a brain-inspired continual learning method that detects concept drift and allocates dedicated sparse neural paths called *concept cells* for each task, enabling efficient and replay-free learning without forgetting. It outperforms state-of-the-art and even offline supervised training in online data-incremental scenarios. Read on for a brief overview of our key findings üòä\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8770dc",
   "metadata": {},
   "source": [
    "## ‚ùî The Problem: AI's Short-Term Memory\n",
    "Traditional neural networks are great at recognizing patterns when all data is presented at once. But in the real world, data arrives bit by bit, like a movie watched frame by frame. Most AI systems fall apart here, suffering from catastrophic forgetting, where learning something new erases what was previously learned. Even worse, many current solutions rely on replaying old data (which isn‚Äôt always possible due to privacy) or growing the model's architecture indefinitely (which becomes inefficient fast)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8c208",
   "metadata": {},
   "source": [
    "## üëßüèª SERENA: Self-Regulated Neurogenesis meets Continual Learning\n",
    "\n",
    "Our new approach takes its inspirations directly from the brain's remarkable ability of \"self-regulated neurogenesis\" to learn and adapt throughout life. It promises to revolutionize how AI handles dynamic, real-world data streams. Specifically, it detects new concepts on its own and carves paths called concept cells which are embedded in a single over-parameterized network, meaning no model growth, no replay buffer. Once a concept is mastered, its corresponding concept cell is \"frozen\", effectively safeguarding that knowledge from future interference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d09f65",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "<img src=\"../images/blogs/serena/teaser.webp\" alt=\"Teaser for SERENA.\" style=\"width:60%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ba41e",
   "metadata": {},
   "source": [
    "## üß† How SERENA Works Its Magic\n",
    "\n",
    "SERENA's design allows it to operate in real-time, online data-incremental learning scenarios without needing explicit task identifiers or multiple training epochs. Here's a simplified look at its core mechanisms:\n",
    "\n",
    "\n",
    "- **Zero-Cost Path Allocation:** When a new concept is detected in the data stream, SERENA allocates a new specialized neural path. This is done efficiently using zero-cost random unstructured pruning. \n",
    "\n",
    "\n",
    "- **Drift Detection:** If the model notices it's struggling (via accuracy dips), it knows something new is happening and carves a new concept cell.\n",
    "\n",
    "\n",
    "- **Knowledge Preservation:** After a concept is learned, its dedicated concept cell is frozen, preventing catastrophic forgetting. This means the model doesn't need to \"re-learn\" old information but can benefit from the existing knowledge while learning the new ones. \n",
    "\n",
    "\n",
    "- **Recency-Effect with Ensemble Inference:** When making decisions, SERENA doesn't rely on a single neural path. Instead, it employs a neuro-inspired ensemble approach, giving more weight to recently acquired knowledge while still integrating past information. This *\"recency effect\"* enhances adaptability to evolving data distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca5c1f",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "<img src=\"../images/blogs/serena/graphs.webp\" alt=\"Results as a Figure.\" style=\"width:60%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa4557",
   "metadata": {},
   "source": [
    "## üöÄ Performance That Surpasses the Best\n",
    "\n",
    "Across over ten benchmarks, SERENA doesn‚Äôt just outperform all continual learning baselines, it even beats offline supervised batch learning which sees all data in advance and gets to train on it many times.\n",
    "Let that sink in: a one-pass, online, biologically inspired method outperforms traditional training.\n",
    "\n",
    "This is a monumental achievement, as offline learning typically has the luxury of revisiting data multiple times. SERENA achieves this superior performance without the need for storing subsets of data for replay or expanding the network architecture, addressing critical concerns around computational overhead,privacy, and memory limitations, so it is game-changer and highly *\"Real-World Ready\"* üåç. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e9ed7",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "<img src=\"../images/blogs/serena/tsne.webp\" alt=\"T-sne comparison.\" style=\"width:60%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2cb48c",
   "metadata": {},
   "source": [
    "## üí° Final Thoughts and Wrapping It Up\n",
    "SERENA is more than a clever acronym‚Äîit represents a significant leap forward in making AI truly adaptive and intelligent. By drawing inspiration from how our brains learn, it shows that continual learning in AI doesn‚Äôt have to be clunky, memory-hungry, or brittle.\n",
    "It can be elegant. Efficient. And maybe... just a little bit human. If you want to know more, you can check the [paper](https://arxiv.org/abs/2403.14684) üòä\n",
    "\n",
    "Stay curious, keep exploring, and let‚Äôs continue pushing the boundaries of what intelligent systems can achieve! üß†üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f68271",
   "metadata": {},
   "source": [
    "---\n",
    "This post was written by Murat Onur Yildirim and need not reflect the view of co-authors."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
